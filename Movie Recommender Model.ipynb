{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loaded with 4806 movies\n",
      "Calculating weighted ratings...\n",
      "Mean vote average: 6.09\n",
      "90th percentile vote count: 1845.5\n",
      "Qualified movies: 481\n",
      "Top 10 movies by weighted score:\n",
      "                                              title  vote_average  vote_count  \\\n",
      "1883                       The Shawshank Redemption           8.5        8205   \n",
      "662                                      Fight Club           8.3        9413   \n",
      "65                                  The Dark Knight           8.2       12002   \n",
      "3235                                   Pulp Fiction           8.3        8428   \n",
      "96                                        Inception           8.1       13752   \n",
      "3340                                  The Godfather           8.4        5893   \n",
      "95                                     Interstellar           8.1       10867   \n",
      "809                                    Forrest Gump           8.2        7927   \n",
      "329   The Lord of the Rings: The Return of the King           8.1        8064   \n",
      "1992                        The Empire Strikes Back           8.2        5879   \n",
      "\n",
      "         score  \n",
      "1883  8.058068  \n",
      "662   7.938270  \n",
      "65    7.919228  \n",
      "3235  7.903588  \n",
      "96    7.862562  \n",
      "3340  7.849882  \n",
      "95    7.808677  \n",
      "809   7.802150  \n",
      "329   7.726274  \n",
      "1992  7.696668  \n",
      "Processing movie features...\n",
      "Sample processed features:\n",
      "Title: The Shawshank Redemption\n",
      "Genres: ['Drama', 'Crime', 'Drama', 'Crime']...\n",
      "Keywords: ['prison', 'corruption', 'policebrutality', 'prisoncell', 'delinquent']...\n",
      "Cast: ['TimRobbins', 'MorganFreeman', 'BobGunton']\n",
      "Director: ['FrankDarabont', 'FrankDarabont', 'FrankDarabont']\n",
      "Creating combined tags...\n",
      "Final dataset shape: (481, 4)\n",
      "Sample tags:\n",
      "framed in the 1940s for the double murder of his wife and her lover, upstanding banker andy dufresne begins a new life at the shawshank prison, where he puts his accounting skills to work for an amora...\n",
      "Applying stemming to reduce word variations...\n",
      "Sample stemmed tags:\n",
      "frame in the 1940 for the doubl murder of hi wife and her lover, upstand banker andi dufresn begin a new life at the shawshank prison, where he put hi account skill to work for an amor warden. dure hi...\n",
      "Creating TF-IDF vectors...\n",
      "TF-IDF vector shape: (481, 5000)\n",
      "Feature names sample: ['000' '007' '10' '12' '13' '15' '150' '15thcenturi' '18thcenturi' '1910']\n",
      "Computing cosine similarity matrix...\n",
      "Similarity matrix shape: (481, 481)\n",
      "Sample similarities for first movie: [1.         0.01110563 0.02203725 0.01778298 0.01946961]\n",
      "\n",
      "Testing recommendations for: The Shawshank Redemption\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1883 is out of bounds for axis 0 with size 481",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 223\u001b[39m\n\u001b[32m    221\u001b[39m test_movie = new_df.iloc[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    222\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTesting recommendations for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_movie\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m test_recommendations = \u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_movie\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, rec \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_recommendations, \u001b[32m1\u001b[39m):\n\u001b[32m    225\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrec[\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrec[\u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Similarity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrec[\u001b[33m'\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 206\u001b[39m, in \u001b[36mrecommend\u001b[39m\u001b[34m(movie, movies_df, similarity_matrix)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMovie not found\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m distances = \u001b[43msimilarity_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    207\u001b[39m movies_list = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(distances)), reverse=\u001b[38;5;28;01mTrue\u001b[39;00m, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m1\u001b[39m])\n\u001b[32m    209\u001b[39m recommendations = []\n",
      "\u001b[31mIndexError\u001b[39m: index 1883 is out of bounds for axis 0 with size 481"
     ]
    }
   ],
   "source": [
    "# Movie Recommendation System - Complete Implementation\n",
    "\n",
    "# Cell 1: Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Cell 2: Load and merge datasets\n",
    "print(\"Loading datasets...\")\n",
    "movies_raw = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits_raw = pd.read_csv('tmdb_5000_credits.csv')\n",
    "\n",
    "# Merge datasets on title\n",
    "movies = movies_raw.merge(credits_raw, on='title')\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew', 'vote_average', 'vote_count']]\n",
    "movies.dropna(inplace=True)\n",
    "\n",
    "print(f\"Dataset loaded with {len(movies)} movies\")\n",
    "movies.head()\n",
    "\n",
    "# Cell 3: Calculate weighted ratings using IMDB formula\n",
    "print(\"Calculating weighted ratings...\")\n",
    "\n",
    "# Calculate the mean vote across all movies (C)\n",
    "C = movies['vote_average'].mean()\n",
    "print(f\"Mean vote average: {C:.2f}\")\n",
    "\n",
    "# Calculate the minimum number of votes required (90th percentile) (m)\n",
    "m = movies['vote_count'].quantile(0.9)\n",
    "print(f\"90th percentile vote count: {m}\")\n",
    "\n",
    "# Filter movies that meet the minimum vote count threshold\n",
    "q_movies = movies.copy().loc[movies['vote_count'] >= m]\n",
    "print(f\"Qualified movies: {len(q_movies)}\")\n",
    "\n",
    "# Function to calculate weighted rating based on IMDB formula\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    return (v / (v + m) * R) + (m / (v + m) * C)\n",
    "\n",
    "# Add the 'score' column to qualified movies\n",
    "q_movies['score'] = q_movies.apply(weighted_rating, axis=1)\n",
    "\n",
    "# Sort movies by score in descending order\n",
    "q_movies = q_movies.sort_values('score', ascending=False)\n",
    "\n",
    "# Display top movies by weighted score\n",
    "print(\"Top 10 movies by weighted score:\")\n",
    "print(q_movies[['title', 'vote_average', 'vote_count', 'score']].head(10))\n",
    "\n",
    "# Use qualified movies for our recommendation model\n",
    "movies = q_movies.copy()\n",
    "\n",
    "# Cell 4: Define helper functions for data processing\n",
    "def convert(text):\n",
    "    \"\"\"Convert JSON-like strings to list of names\"\"\"\n",
    "    L = []\n",
    "    try:\n",
    "        for i in ast.literal_eval(text):\n",
    "            L.append(i['name'])\n",
    "    except:\n",
    "        pass\n",
    "    return L\n",
    "\n",
    "def convert_cast(text):\n",
    "    \"\"\"Get top 3 cast members\"\"\"\n",
    "    L = []\n",
    "    counter = 0\n",
    "    try:\n",
    "        for i in ast.literal_eval(text):\n",
    "            if counter < 3:\n",
    "                L.append(i['name'])\n",
    "                counter += 1\n",
    "    except:\n",
    "        pass\n",
    "    return L\n",
    "\n",
    "def fetch_director(text):\n",
    "    \"\"\"Fetch director name from crew\"\"\"\n",
    "    L = []\n",
    "    try:\n",
    "        for i in ast.literal_eval(text):\n",
    "            if i['job'] == 'Director':\n",
    "                L.append(i['name'])\n",
    "                break\n",
    "    except:\n",
    "        pass\n",
    "    return L\n",
    "\n",
    "def collapse(L):\n",
    "    \"\"\"Remove spaces between names to create single tags\"\"\"\n",
    "    L1 = []\n",
    "    for i in L:\n",
    "        L1.append(i.replace(\" \", \"\"))\n",
    "    return L1\n",
    "\n",
    "# Cell 5: Define weighted processing functions\n",
    "def process_genres(obj):\n",
    "    \"\"\"Process and weight genres by repeating them\"\"\"\n",
    "    return collapse(convert(obj)) * 2  # Weight genres more\n",
    "\n",
    "def process_keywords(obj):\n",
    "    \"\"\"Process and weight keywords by repeating them\"\"\"\n",
    "    return collapse(convert(obj)) * 2  # Weight keywords more\n",
    "\n",
    "def process_director(obj):\n",
    "    \"\"\"Process and weight director by repeating them\"\"\"\n",
    "    return collapse(fetch_director(obj)) * 3  # Weight director most\n",
    "\n",
    "# Cell 6: Apply transformations with weighting\n",
    "print(\"Processing movie features...\")\n",
    "\n",
    "# Apply weighted processing to increase importance of key features\n",
    "movies['genres'] = movies['genres'].apply(process_genres)\n",
    "movies['keywords'] = movies['keywords'].apply(process_keywords)\n",
    "movies['cast'] = movies['cast'].apply(convert_cast).apply(collapse)\n",
    "movies['crew'] = movies['crew'].apply(process_director)  # This now contains weighted directors\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split() if pd.notna(x) else [])\n",
    "\n",
    "# Display sample processed data\n",
    "print(\"Sample processed features:\")\n",
    "sample_movie = movies.iloc[0]\n",
    "print(f\"Title: {sample_movie['title']}\")\n",
    "print(f\"Genres: {sample_movie['genres'][:5]}...\")  # Show first 5 elements\n",
    "print(f\"Keywords: {sample_movie['keywords'][:5]}...\")\n",
    "print(f\"Cast: {sample_movie['cast']}\")\n",
    "print(f\"Director: {sample_movie['crew']}\")\n",
    "\n",
    "# Cell 7: Create tags and final dataframe\n",
    "print(\"Creating combined tags...\")\n",
    "\n",
    "# Combine all processed features into a single 'tags' column\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    "\n",
    "# Create the final dataframe with essential columns\n",
    "new_df = movies[['movie_id', 'title', 'tags', 'score']].copy()\n",
    "\n",
    "# Convert the list of tags into a single, lowercase string\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x).lower())\n",
    "\n",
    "print(f\"Final dataset shape: {new_df.shape}\")\n",
    "print(\"Sample tags:\")\n",
    "print(new_df.iloc[0]['tags'][:200] + \"...\")\n",
    "\n",
    "# Cell 8: Apply stemming\n",
    "print(\"Applying stemming to reduce word variations...\")\n",
    "\n",
    "# Initialize Porter Stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(text):\n",
    "    \"\"\"Apply stemming to text\"\"\"\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)\n",
    "\n",
    "# Apply stemming to tags\n",
    "new_df['tags'] = new_df['tags'].apply(stem)\n",
    "\n",
    "print(\"Sample stemmed tags:\")\n",
    "print(new_df.iloc[0]['tags'][:200] + \"...\")\n",
    "\n",
    "# Cell 9: Create TF-IDF vectors\n",
    "print(\"Creating TF-IDF vectors...\")\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "# Transform tags into numerical vectors\n",
    "vectors = tfidf.fit_transform(new_df['tags']).toarray()\n",
    "\n",
    "print(f\"TF-IDF vector shape: {vectors.shape}\")\n",
    "print(f\"Feature names sample: {tfidf.get_feature_names_out()[:10]}\")\n",
    "\n",
    "# Cell 10: Calculate cosine similarity\n",
    "print(\"Computing cosine similarity matrix...\")\n",
    "\n",
    "# Calculate cosine similarity between all movies\n",
    "similarity = cosine_similarity(vectors)\n",
    "\n",
    "print(f\"Similarity matrix shape: {similarity.shape}\")\n",
    "print(f\"Sample similarities for first movie: {similarity[0][:5]}\")\n",
    "\n",
    "# Cell 11: Test the recommendation function\n",
    "def recommend(movie, movies_df, similarity_matrix):\n",
    "    \"\"\"Test function to get basic recommendations\"\"\"\n",
    "    try:\n",
    "        index = movies_df[movies_df['title'] == movie].index[0]\n",
    "    except IndexError:\n",
    "        return \"Movie not found\"\n",
    "    \n",
    "    distances = similarity_matrix[index]\n",
    "    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])\n",
    "    \n",
    "    recommendations = []\n",
    "    for i in movies_list[1:6]:  # Top 5, excluding the movie itself\n",
    "        movie_info = movies_df.iloc[i[0]]\n",
    "        recommendations.append({\n",
    "            'title': movie_info['title'],\n",
    "            'score': round(movie_info['score'], 2),\n",
    "            'similarity': round(i[1], 3)\n",
    "        })\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Test with a popular movie\n",
    "test_movie = new_df.iloc[0]['title']\n",
    "print(f\"\\nTesting recommendations for: {test_movie}\")\n",
    "test_recommendations = recommend(test_movie, new_df, similarity)\n",
    "for i, rec in enumerate(test_recommendations, 1):\n",
    "    print(f\"{i}. {rec['title']} (Score: {rec['score']}, Similarity: {rec['similarity']})\")\n",
    "\n",
    "# Cell 12: Save the model and data\n",
    "print(\"\\nSaving model files...\")\n",
    "\n",
    "# Save the processed dataframe and similarity matrix\n",
    "pickle.dump(new_df.to_dict(), open('movies_list_enhanced.pkl', 'wb'))\n",
    "pickle.dump(similarity, open('similarity_enhanced.pkl', 'wb'))\n",
    "\n",
    "print(\"Model and data saved successfully!\")\n",
    "print(\"Files created:\")\n",
    "print(\"- movies_list_enhanced.pkl\")\n",
    "print(\"- similarity_enhanced.pkl\")\n",
    "\n",
    "# Cell 13: Verify saved files\n",
    "print(\"\\nVerifying saved files...\")\n",
    "\n",
    "# Load and verify the saved files\n",
    "try:\n",
    "    loaded_movies = pickle.load(open('movies_list_enhanced.pkl', 'rb'))\n",
    "    loaded_similarity = pickle.load(open('similarity_enhanced.pkl', 'rb'))\n",
    "    \n",
    "    loaded_df = pd.DataFrame(loaded_movies)\n",
    "    \n",
    "    print(f\"Loaded movies shape: {loaded_df.shape}\")\n",
    "    print(f\"Loaded similarity shape: {loaded_similarity.shape}\")\n",
    "    print(\"✅ Files loaded successfully!\")\n",
    "    \n",
    "    # Test one more recommendation with loaded data\n",
    "    print(f\"\\nFinal test with loaded data for: {test_movie}\")\n",
    "    final_test = recommend(test_movie, loaded_df, loaded_similarity)\n",
    "    for i, rec in enumerate(final_test[:3], 1):\n",
    "        print(f\"{i}. {rec['title']} (Score: {rec['score']})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading files: {e}\")\n",
    "\n",
    "print(\"\\n🎉 Movie Recommendation System setup complete!\")\n",
    "print(\"You can now run the Streamlit app with: streamlit run app.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
